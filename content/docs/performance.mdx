---
title: "Performance"
description: "Optimize your Elide applications for maximum performance"
date: "2025-11-20"
---

# Performance

Learn how to build high-performance applications with Elide.

## Performance Overview

Elide delivers exceptional performance through:

- **GraalVM JIT**: Advanced just-in-time compilation
- **Native Image**: Ahead-of-time compilation for instant startup
- **Polyglot Optimization**: Shared runtime optimizations
- **Zero-Copy Operations**: Efficient data handling

## Startup Performance

### JIT Mode

| Metric | Value |
|--------|-------|
| **Cold Start** | ~100ms |
| **Warmup Time** | 2-5 seconds |
| **Peak Performance** | 20-50x faster than warmup |

### Native Image

| Metric | Value |
|--------|-------|
| **Cold Start** | < 10ms |
| **Memory (Base)** | ~10MB |
| **Startup** | Instant |
| **Performance** | Near-peak immediately |

## Memory Usage

### Compared to Other Runtimes

| Runtime | Hello World | HTTP Server | Full App |
|---------|-------------|-------------|----------|
| **Elide (Native)** | ~10MB | ~20MB | ~50MB |
| **Node.js** | ~50MB | ~80MB | ~200MB |
| **Python** | ~40MB | ~70MB | ~150MB |
| **Deno** | ~40MB | ~60MB | ~120MB |

## HTTP Performance

### Throughput Benchmarks

```bash
# Run benchmark
elide benchmark http-server.js
```

| Metric | Elide (Native) | Node.js | Deno |
|--------|----------------|---------|------|
| **Requests/sec** | 800K+ | 200K | 300K |
| **Latency (p50)** | < 1ms | 5ms | 3ms |
| **Latency (p99)** | 2ms | 20ms | 15ms |

### Configuration for Max Throughput

```javascript
const server = Elide.http.createServer({
  port: 8080,
  backlog: 1024,
  keepAlive: true,
  tcpNoDelay: true,
  reusePort: true
})
```

## Optimization Techniques

### 1. Use Native Compilation

```bash
# Build for production
elide build --native --optimize
```

Benefits:
- ‚ö° Instant startup
- üíæ Minimal memory
- üöÄ Consistent performance

### 2. Profile Your Code

```bash
# CPU profiling
elide run --cpuprofile app.js

# Memory profiling
elide run --heapprofile app.js
```

Analyze with Chrome DevTools.

### 3. Optimize Hot Paths

```javascript
// ‚ùå Avoid: Object creation in loops
for (let i = 0; i < 1000000; i++) {
  const obj = { value: i } // Creates 1M objects
}

// ‚úÖ Better: Reuse objects
const obj = { value: 0 }
for (let i = 0; i < 1000000; i++) {
  obj.value = i
}
```

### 4. Use Appropriate Data Structures

```javascript
// ‚ùå Slow for lookups
const array = [1, 2, 3, 4, 5]
array.includes(3) // O(n)

// ‚úÖ Fast for lookups
const set = new Set([1, 2, 3, 4, 5])
set.has(3) // O(1)
```

### 5. Minimize Polyglot Calls

```javascript
// ‚ùå Avoid: Many small calls
for (let i = 0; i < 1000; i++) {
  pythonModule.process(data[i])
}

// ‚úÖ Better: Batch operations
pythonModule.processBatch(data)
```

## Polyglot Performance

### Zero-Copy Buffers

```javascript
// Create large buffer
const buffer = new Uint8Array(1000000)

// Pass to Python without copying
const result = python.processBuffer(buffer)
```

### Function Call Overhead

| Call Type | Overhead |
|-----------|----------|
| JavaScript ‚Üí JavaScript | ~0ns |
| JavaScript ‚Üí Python | ~10-100ns |
| With type conversion | ~100-1000ns |

## Native Image Optimizations

### Build Configuration

```pkl
// elide.pkl
build {
  native {
    optimize = true
    pgo = true // Profile-Guided Optimization
    stripDebug = true
    compression = "upx"
  }
}
```

### Profile-Guided Optimization (PGO)

```bash
# Step 1: Build instrumented binary
elide build --native --pgo-instrument

# Step 2: Run typical workload
./app-instrumented

# Step 3: Build optimized binary
elide build --native --pgo-use
```

Results in 10-30% performance improvement.

## Async Best Practices

### Use Async/Await Properly

```javascript
// ‚ùå Sequential (slow)
const user = await fetchUser()
const posts = await fetchPosts()
const comments = await fetchComments()

// ‚úÖ Parallel (fast)
const [user, posts, comments] = await Promise.all([
  fetchUser(),
  fetchPosts(),
  fetchComments()
])
```

### Avoid Blocking Operations

```javascript
// ‚ùå Blocks event loop
const data = fs.readFileSync('large-file.dat')

// ‚úÖ Non-blocking
const data = await fs.readFile('large-file.dat')
```

## Caching Strategies

### In-Memory Caching

```javascript
const cache = new Map()

async function getCachedData(key) {
  if (cache.has(key)) {
    return cache.get(key)
  }
  
  const data = await fetchData(key)
  cache.set(key, data)
  return data
}
```

### HTTP Caching

```javascript
app.router.handle("GET", "/api/data", (req, res) => {
  res.headers.set('Cache-Control', 'public, max-age=3600')
  res.headers.set('ETag', generateETag(data))
  res.json(data)
})
```

## Database Optimization

### Connection Pooling

```javascript
const pool = createPool({
  host: 'localhost',
  database: 'myapp',
  min: 5,
  max: 20,
  idleTimeoutMillis: 30000
})
```

### Query Optimization

```javascript
// ‚ùå N+1 queries
for (const user of users) {
  const posts = await db.query('SELECT * FROM posts WHERE user_id = ?', [user.id])
}

// ‚úÖ Single query
const posts = await db.query('SELECT * FROM posts WHERE user_id IN (?)', [userIds])
```

## Monitoring Performance

### Built-in Metrics

```javascript
// Enable metrics
app.metrics.enable()

// Expose metrics endpoint
app.router.handle("GET", "/metrics", (req, res) => {
  res.json(app.metrics.getAll())
})
```

### Custom Metrics

```javascript
const timer = app.metrics.timer('request_duration')

app.use((req, res, next) => {
  const start = timer.start()
  
  res.on('finish', () => {
    timer.stop(start)
  })
  
  next()
})
```

## Load Testing

### Using wrk

```bash
# Install wrk
brew install wrk

# Run load test
wrk -t12 -c400 -d30s http://localhost:8080/
```

### Using autocannon

```bash
# Install autocannon
npm install -g autocannon

# Run test
autocannon -c 100 -d 30 http://localhost:8080/
```

## Performance Checklist

‚úÖ **Build**
- [ ] Use native compilation for production
- [ ] Enable optimizations
- [ ] Consider PGO for critical paths

‚úÖ **Code**
- [ ] Profile before optimizing
- [ ] Minimize object allocations
- [ ] Use appropriate data structures
- [ ] Batch polyglot operations

‚úÖ **HTTP**
- [ ] Enable keep-alive
- [ ] Use compression
- [ ] Implement caching
- [ ] Optimize payload sizes

‚úÖ **Database**
- [ ] Use connection pooling
- [ ] Optimize queries
- [ ] Add appropriate indexes
- [ ] Cache frequent queries

‚úÖ **Monitoring**
- [ ] Enable metrics
- [ ] Set up alerting
- [ ] Monitor memory usage
- [ ] Track response times

## Benchmarking Tips

1. **Warmup First**: Run several iterations before measuring
2. **Consistent Environment**: Same hardware, no other load
3. **Multiple Runs**: Average results from multiple runs
4. **Real Workloads**: Test with production-like data
5. **Measure What Matters**: Focus on user-facing metrics

## Common Performance Pitfalls

### 1. Premature Optimization

```javascript
// ‚ùå Don't optimize without measuring
function complexOptimization(x) {
  // Micro-optimizations that don't matter
}

// ‚úÖ Profile first, then optimize hot paths
```

### 2. Memory Leaks

```javascript
// ‚ùå Leaks memory
const cache = new Map()
setInterval(() => {
  cache.set(Date.now(), fetchData()) // Never cleaned up
}, 1000)

// ‚úÖ Implement cleanup
const cache = new LRUCache({ max: 1000 })
```

### 3. Blocking the Event Loop

```javascript
// ‚ùå Blocks for 1 second
function heavyComputation() {
  const start = Date.now()
  while (Date.now() - start < 1000) {
    // CPU-intensive work
  }
}

// ‚úÖ Use Web Workers or offload to Python
```

## Resources

- [GraalVM Performance Guide](https://www.graalvm.org/latest/reference-manual/performance/)
- [Profiling Tools](/docs/debugging#performance-profiling)
- [Native Image Guide](https://www.graalvm.org/latest/reference-manual/native-image/)

